{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd519168",
   "metadata": {},
   "source": [
    "# Initial Model Testing with new Sequence Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2297abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "#Keras\n",
    "from tensorflow import keras\n",
    "from tensorflow import stack, Tensor\n",
    "from keras import Sequential, layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.utils import timeseries_dataset_from_array\n",
    "from tensorflow import data\n",
    "\n",
    "\n",
    "\n",
    "#Project imports \n",
    "from bdi_predict.model.data import clean_data\n",
    "from bdi_predict.model.preprocessor import train_val_test_split, min_max_scaler\n",
    "from bdi_predict.model.sequencer import SequenceGenerator\n",
    "from bdi_predict.model.params import BASE_PROJECT_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "236138f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e54111c",
   "metadata": {},
   "source": [
    "## Preprocessing - (splitting data, scaling, and creating sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90d2251d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BDRY</th>\n",
       "      <th>BDI</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-23</th>\n",
       "      <td>24.1005</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>-0.024735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-26</th>\n",
       "      <td>24.8400</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>0.013126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-27</th>\n",
       "      <td>24.0800</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>-0.013495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               BDRY     BDI    target\n",
       "time                                 \n",
       "2018-03-23  24.1005  1122.0 -0.024735\n",
       "2018-03-26  24.8400  1126.0  0.013126\n",
       "2018-03-27  24.0800  1117.0 -0.013495"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/cleaned_data.csv\")\n",
    "df = df.drop(columns=\"log_BDRY\").copy()\n",
    "df.set_index(\"time\", inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f28d1f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into train, validation, and test datasets.\n"
     ]
    }
   ],
   "source": [
    "dfs = train_val_test_split(df=df, train_val_test_ratio=(7,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef78a820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets min-max scaled.\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test = min_max_scaler(dfs=dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb766fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BDRY</th>\n",
       "      <th>BDI</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.769748</td>\n",
       "      <td>0.240992</td>\n",
       "      <td>0.337520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.797941</td>\n",
       "      <td>0.242314</td>\n",
       "      <td>0.531249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.768967</td>\n",
       "      <td>0.239339</td>\n",
       "      <td>0.395035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BDRY       BDI    target\n",
       "0  0.769748  0.240992  0.337520\n",
       "1  0.797941  0.242314  0.531249\n",
       "2  0.768967  0.239339  0.395035"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f32d293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BDRY</th>\n",
       "      <th>BDI</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.865040</td>\n",
       "      <td>0.984463</td>\n",
       "      <td>0.453253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.858178</td>\n",
       "      <td>0.984463</td>\n",
       "      <td>0.448999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.880671</td>\n",
       "      <td>0.985785</td>\n",
       "      <td>0.513167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BDRY       BDI    target\n",
       "0  0.865040  0.984463  0.453253\n",
       "1  0.858178  0.984463  0.448999\n",
       "2  0.880671  0.985785  0.513167"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae9086f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BDRY</th>\n",
       "      <th>BDI</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.462066</td>\n",
       "      <td>0.598678</td>\n",
       "      <td>0.417447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.488753</td>\n",
       "      <td>0.592727</td>\n",
       "      <td>0.559068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.505528</td>\n",
       "      <td>0.610579</td>\n",
       "      <td>0.521776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BDRY       BDI    target\n",
       "0  0.462066  0.598678  0.417447\n",
       "1  0.488753  0.592727  0.559068\n",
       "2  0.505528  0.610579  0.521776"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d416bcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total sequence size: 21\n",
       "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
       "Target indice(s): [20]\n",
       "Target column name(s): ['target']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiating a SequenceGenerator Class\n",
    "\n",
    "Sequencer = SequenceGenerator(input_width=20,\n",
    "                                      target_width=1,\n",
    "                                      offset=1,\n",
    "                                      df_train=df_train,\n",
    "                                      df_val=df_val,\n",
    "                                     df_test=df_test,\n",
    "                                     target_columns=[\"target\"])\n",
    "\n",
    "Sequencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cb13d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understand how exactly the split_sequence works by understading what exactly I need to feed in and in what manner\n",
    "#for the LSTM model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a662799c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got slice(20, None, None)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Inputting a tf.Tensor made up of 8 slices \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#(the 8 seuqnecs that make up a single batch of batch_size=8) to generate\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Stack 8 slices, the length of the total window.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# FIX THIS!\u001b[39;00m\n\u001b[1;32m      6\u001b[0m example_sequence \u001b[38;5;241m=\u001b[39m stack([np\u001b[38;5;241m.\u001b[39marray(df_train[:Sequencer\u001b[38;5;241m.\u001b[39mtotal_sequence_size]),\n\u001b[1;32m      7\u001b[0m                            np\u001b[38;5;241m.\u001b[39marray(df_train[\u001b[38;5;241m100\u001b[39m:\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m+\u001b[39mSequencer\u001b[38;5;241m.\u001b[39mtotal_sequence_size]),\n\u001b[1;32m      8\u001b[0m                            np\u001b[38;5;241m.\u001b[39marray(df_train[\u001b[38;5;241m200\u001b[39m:\u001b[38;5;241m200\u001b[39m\u001b[38;5;241m+\u001b[39mSequencer\u001b[38;5;241m.\u001b[39mtotal_sequence_size])])\n\u001b[0;32m---> 10\u001b[0m example_inputs, example_targets \u001b[38;5;241m=\u001b[39m \u001b[43mSequencer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample_sequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll shapes are: (batch, time, features)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSequence shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_sequence\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/code/LeibnizianOptimist/bdi_predict_v2/bdi_predict/model/sequencer.py:92\u001b[0m, in \u001b[0;36mSequenceGenerator.split_sequence\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03mThis instance method converts a list of consecutive inputs \u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03minto a seperate sequence of inputs with a corresponding seperate sequence of targets.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03mIt takes an an input a tf.Tensor wherein each row represents a single sequence that constitue a batch fed to the \u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03mLSTM model. \u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m inputs \u001b[38;5;241m=\u001b[39m features[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_slice, :]\n\u001b[0;32m---> 92\u001b[0m targets \u001b[38;5;241m=\u001b[39m \u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_slice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_columns \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m   targets \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstack(\n\u001b[1;32m     96\u001b[0m     [targets[:, :, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumn_index[name]] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_columns], \n\u001b[1;32m     97\u001b[0m     axis\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     98\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/bdi_predict_v2/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/bdi_predict_v2/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:906\u001b[0m, in \u001b[0;36m_check_index\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m    901\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(idx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _SUPPORTED_SLICE_DTYPES \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    903\u001b[0m     idx\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(idx\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    904\u001b[0m   \u001b[38;5;66;03m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[39;00m\n\u001b[1;32m    905\u001b[0m   \u001b[38;5;66;03m# will break `_slice_helper` contract.\u001b[39;00m\n\u001b[0;32m--> 906\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(_SLICE_TYPE_ERROR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx))\n",
      "\u001b[0;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got slice(20, None, None)"
     ]
    }
   ],
   "source": [
    "# Inputting a tf.Tensor made up of 8 slices \n",
    "#(the 8 seuqnecs that make up a single batch of batch_size=8) to generate\n",
    "\n",
    "# Stack 8 slices, the length of the total window.\n",
    "# FIX THIS!\n",
    "example_sequence = stack([np.array(df_train[:Sequencer.total_sequence_size]),\n",
    "                           np.array(df_train[100:100+Sequencer.total_sequence_size]),\n",
    "                           np.array(df_train[200:200+Sequencer.total_sequence_size])])\n",
    "\n",
    "example_inputs, example_targets = Sequencer.split_sequence(example_sequence)\n",
    "\n",
    "print('All shapes are: (batch, time, features)')\n",
    "print(f'Sequence shape: {example_sequence.shape}')\n",
    "print(f'Inputs shape: {example_inputs.shape}')\n",
    "print(f'targets shape: {example_targets.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "905f465a",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), slice(0, 20, None), slice(None, None, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/bdi_predict_v2/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/bdi_predict_v2/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/bdi_predict_v2/lib/python3.10/site-packages/pandas/_libs/index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), slice(0, 20, None), slice(None, None, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m \u001b[43mSequencer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSequencer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/LeibnizianOptimist/bdi_predict_v2/bdi_predict/model/sequencer.py:88\u001b[0m, in \u001b[0;36mSequenceGenerator.split_sequence\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_sequence\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     82\u001b[0m                    df:pd\u001b[38;5;241m.\u001b[39mDataFrame\n\u001b[1;32m     83\u001b[0m                    ):\n\u001b[1;32m     84\u001b[0m   \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m  This instance method converts a list of consecutive inputs into a seperate sequence of inputs with a corresponding seperate sequence of targets.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_slice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     89\u001b[0m   targets \u001b[38;5;241m=\u001b[39m df[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_slice, :]\n\u001b[1;32m     91\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_columns \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/bdi_predict_v2/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/bdi_predict_v2/lib/python3.10/site-packages/pandas/core/indexes/base.py:3810\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m         \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3810\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;66;03m# GH#42269\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/bdi_predict_v2/lib/python3.10/site-packages/pandas/core/indexes/base.py:5968\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5964\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   5965\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5966\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5967\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5968\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), slice(0, 20, None), slice(None, None, None))"
     ]
    }
   ],
   "source": [
    "inputs, targets = Sequencer.split_sequence(df=Sequencer.df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d18f29f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice(8, 20, None)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SequenceGenerator.input_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "140fe140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    \n",
    "    \"\"\" \n",
    "    Initialize the LSTM Reucrrent Neural Network.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nInitialising model...\")\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    #LSTM LAYERS:\n",
    "    \n",
    "    model.add(layers.LSTM(60,\n",
    "                          activation=\"tanh\",\n",
    "                          input_shape=(20,2),\n",
    "                          return_sequences=False))\n",
    "\n",
    "    #DENSE LAYERS:\n",
    "    \n",
    "    model.add(layers.Dense(25, activation=\"relu\"))\n",
    "    model.add(layers.Dense(1, activation=\"linear\"))\n",
    "    \n",
    "    print(\"\\nmodel initialized.\")\n",
    "\n",
    "    #SETTING UP OPTIMIZERS:\n",
    "    \n",
    "    lr_schedule = ExponentialDecay(initial_learning_rate=1e-3,\n",
    "                                   decay_steps=10000,\n",
    "                                   decay_rate=0.9)\n",
    "    \n",
    "    rmsprop = RMSprop(learning_rate=lr_schedule)\n",
    "    \n",
    "    #COMPILING MODEL:\n",
    "    \n",
    "    model.compile(loss=\"mse\",\n",
    "                  optimizer=rmsprop,\n",
    "                  metrics=\"mae\")\n",
    "    print(\"\\nmodel compiled.\")\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938ea715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68afb5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model:keras.Sequential,\n",
    "                XandY:data.Dataset,\n",
    "                patience=10,\n",
    "                validation_data=data.Dataset):\n",
    "    \n",
    "    \"\"\"\n",
    "    Fit model and return a the tuple (fitted_model, history)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nTraining model...\")\n",
    "    \n",
    "    #EarlyStopping DEFINITION:\n",
    "    \n",
    "    es = EarlyStopping(monitor=\"val_mae\",\n",
    "                       patience=patience,\n",
    "                       restore_best_weights=True)\n",
    "    \n",
    "    #FITTING MODEL:\n",
    "    \n",
    "    history = model.fit(XandY,\n",
    "                        epochs=100,\n",
    "                        validation_data=validation_data,\n",
    "                        shuffle=True,\n",
    "                        callbacks=es)\n",
    "    \n",
    "    \n",
    "    print(f\"\\nmodel trained ({len(XandY)} rows).\")\n",
    "     \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "715104a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/cleaned_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
